{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <IMG SRC=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/d5/Fachhochschule_Südwestfalen_20xx_logo.svg/320px-Fachhochschule_Südwestfalen_20xx_logo.svg.png\" WIDTH=250 ALIGN=\"right\">\n",
    "</figure>\n",
    "\n",
    "# Programmierung für KI\n",
    "### Winterersemester 2022/23\n",
    "Prof. Dr. Heiner Giefers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Achtung:** Im folgenden Aufgabenblatt sind einige Funktionen enthalten, die Sie zur Lösung der Aufgaben *verwenden* müssen. Sie müssen die Implementierung der Funktionen nicht unbedingt *verstehen*, um sie zu verwenden. Um möglichst viele Aufgaben zu lösen, verwenden Sie die Funktionen einfach \"wie sie sind\" und schauen Sie sich die Details im Nachgang an."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprache von Texten erkennen\n",
    "\n",
    "In dieser Aufgabe wollen wir uns mit dem Problem beschäftigen, die Sprache zu bestimmen, in der ein gewisser Text verfasst ist.\n",
    "Es gibt verschiedenste Ansätze, dieses Problem zu lösen.\n",
    "Wir werden ein sehr einfaches, Daten-getriebenes Verfahren einsetzen, bei dem die charakteristische *Buchstabenhäufigkeit* einer Sprache verwendet wird.\n",
    "\n",
    "Die Idee ist folgende: In den verschiedenen Sprachen kommen bestimmte Buchstaben unterschiedlich häufig vor.\n",
    "Im Englischen, zum Beispiel, ist das *y* deutlich häufiger als im Deutschen, im Französischen ist das *e* (ohne Akzent) wahrscheinlich seltener als in anderen Sprachen.\n",
    "\n",
    "Wenn wir bestimmen, wie häufig die einzelnen Buchstaben in einer Sprache *im Allgemeinen* vorkommen, haben wir eine Art *Fingerabdruck* der Sprache. Für einen neuen Text, zu dem wir die Sprache nicht kennen, können wir ebenfalls die Buchstabenhäufigkeit berechnen und anschließend diese Verteilung mit allen Sprach-Fingerabdrücken vergleichen. Unsere Annahme ist, dass der Fingerabdruck, zu dem unsere Buchstaben-Verteilung am besten passt, zur Sprache gehört, in der auch der Text verfasst ist.\n",
    "\n",
    "Im Folgenden wollen wir versuchen herauszufinden, ob diese Idee funktioniert. Dazu müssen wir folgende Teilprobleme lösen:\n",
    "\n",
    "1. Wir müssen **Texte in verschiedenen Sprachen beschaffen**. Diese Texte müssen jeweils möglichst repräsentativ für die Sprache sein. Fachtexte oder andere *spezielle* Texte sollten eher vermieden werden.\n",
    "1. Wir müssen in den Texten die Buchstaben analysieren und die **relative Häufigkeit jedes Buchstaben bestimmen**. Dieser Schritt muss für alle Sprachen wiederholt werden.\n",
    "1. Um das Verfahren zu testen, müssen wir neue, diesmal kürzere Textpassagen beschaffen. Wir können die gleichen Funktionen wie im Schritt zuvor verwenden, um die Buchstabenhäufigkeit zu bestimmen.\n",
    "1. Wir benötigen einen Weg um herauszufinden, wie *ähnlich* zwei verschiedene Häufigkeitsverteilungen sind. Wir werden hierfür die **Abweichung zwischen den Verteilungen** bestimmen und das Minimum dieser Abweichungen als Ergebnis auswählen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schritt 1: Texte in verschiedenen Sprachen beschaffen\n",
    "Um die mittleren Buchstabenhäufigkeiten in den verschiedenen Sprachen zu ermitteln, brauchen wir zunächst einmal **Daten**.\n",
    "Eine recht gute Quelle für Texte in verschiedenen Sprachen, ist [Wikipedia](https://www.wikipedia.org).\n",
    "Von dort werden wir verschiedene, zufällige Seiten in den unterschiedlichen Sprachen aufrufen und den Textinhalt dieser Seiten herunterladen.\n",
    "Für den Zugriff auf Wikipedia Seiten empfiehlt sich die Installation des Python-Pakets *Wikipedia-API*.\n",
    "Falls nicht vorhanden, installieren wir dieses Paket direkt aus dem Notebook heraus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_4FRptYMGtde",
    "outputId": "25af9d89-2421-4abe-979d-f1fd52f7df43"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import wikipediaapi\n",
    "except:\n",
    "    import sys\n",
    "    !{sys.executable} -m pip install wikipedia-api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In der nächsten Code-Zelle werden die Methoden `random_page` und `random_text` implementiert.\n",
    "`random_text(size,lang)` liefert einen Text mit `size` Zeichen in der Sprache `lang`.\n",
    "Um zufällige Wikipedia-Seiten herunterzuladen wir die Methode `random_page` verwendet.\n",
    "Wikipedia bietet über die URL [wikipedia.org/wiki/Special:Random](http://wikipedia.org/wiki/Special:Random) die Möglichkeit, eine zufällige Seite auszuwählen.\n",
    "Über diese URL holen wir uns den Titel der zufälligen Seite und laden den Inhalt schließlich mit der Wikipedia-API herunter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ktglnRFmG2j2"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import wikipediaapi\n",
    "\n",
    "def random_page(wiki, lang=\"de\"):\n",
    "    ''' Die Funktion liefert den Inhalt (Text) einer zufälligen \n",
    "    Wikipedia-Seite zurück\n",
    "    \n",
    "    Parameter\n",
    "    --------------------\n",
    "    wiki: Ein \"Wikipedia\"-Objekt des Moduls wikipediaapi\n",
    "    lang: Ein Sprach-Kuerzel, dass die entsprechende Wikipedia-Sprache bezeichnet.\n",
    "          Beispiele sind \"en\" (Englisch), \"de\" (Deutsch), \"es\" (Spanisch), \"fr\" (Französisch).\n",
    "          Default ist \"de\"\n",
    "          \n",
    "    Return\n",
    "    --------------------\n",
    "    Der Inhalt der zufällig ausgewählten Seite\n",
    "    '''\n",
    "    r = requests.get(\"https://\" + lang + \".wikipedia.org/wiki/Special:Random\")\n",
    "    soup = BeautifulSoup(r.content)\n",
    "    # Schneitet 12 Buchstaben vom Ende ab\n",
    "    # Funktioniert nicht bei allen Sprachen\n",
    "    #page = wiki.page(soup.title.text[:-12])\n",
    "    # Such nach \"Wikip\" im Titel\n",
    "    # Nimm den vorderen Teil ohne \" - \" (3 Buchstaben)\n",
    "    title = soup.title.text.split('Wikip')[0]\n",
    "    page = wiki.page(title[:-3])\n",
    "    assert page.exists(), f\"Die Seite {page} in {lang} ibt es nicht\"\n",
    "    return page.text\n",
    "\n",
    "def random_text(size,lang=\"de\"):\n",
    "    ''' Die Funktion liefert einen von Sonderzeichen bereinigten Text\n",
    "    der länge \"size\" (in Zeichen) in der Sprache \"lang\" zurück\n",
    "    \n",
    "    Parameter\n",
    "    --------------------\n",
    "    zize: Die geforderte Länge des Textes in Zeichen\n",
    "    lang: Ein Sprach-Kuerzel, dass die entsprechende Sprache bezeichnet.\n",
    "          Beispiele sind \"en\" (Englisch), \"de\" (Deutsch), \"es\" (Spanisch), \"fr\" (Französisch).\n",
    "          Default ist \"de\"\n",
    "          \n",
    "    Return\n",
    "    --------------------\n",
    "    String der länge \"size\" in der Sprache \"lang\"\n",
    "    '''\n",
    "    WIKI = wikipediaapi.Wikipedia(\n",
    "        language=lang,\n",
    "        extract_format=wikipediaapi.ExtractFormat.WIKI\n",
    "    )\n",
    "    text = ''\n",
    "    while(len(text)<size):\n",
    "        t = random_page(WIKI, lang)\n",
    "        # Übersetze Umlaute\n",
    "        de_table = str.maketrans({'Ä': 'Ae', 'Ö': 'Oe', 'Ü': 'Ue', \n",
    "                          'ä': 'ae', 'ö': 'oe', 'ü': 'ue', 'ß': 'ss'})\n",
    "        t = t.translate(de_table)\n",
    "        # Entferne alles, was kein Buchstabe oder Leerzeichen ist\n",
    "        t_cleaned = re.sub('[^a-zA-Z ]', '', t)\n",
    "        #Alles zu Kleinbuchstaben\n",
    "        t_cleaned = t_cleaned.lower()\n",
    "        text += t_cleaned\n",
    "\n",
    "    return text[:size]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir können nun die Funktion `random_text` verwenden, um einen String mit beliebiger Länge in verschiedenen Sprachen zu erzeugen.\n",
    "Im folgenden Beispiel erzeigen wir einen String `de_text_500` aus dem Deutschen mit genau 500 Zeichen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_text_500 = random_text(500,\"de\")\n",
    "print(de_text_500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zeichenweise durchlaufen, können wir diesen String wie jede Zeichenkette, ganz einfach mit `for`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for z in de_text_500:\n",
    "    #Drucke jedes Zeichen und danach jeweils ein '-'\n",
    "    print(z,end='-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um aus der Zeichenkette auf einzelne Worte zu schließen, müssen wir den Text an den stellen der Leerzeichen *aufsplitten*.\n",
    "\n",
    "**Aufgabe:** Verwenden Sie die Funktion `random_text` um einen Englischen Text mit 200 Zeichen zu erzeugen. Teilen Sie den Text in einzelne Worte auf, die in der Liste `worte` abgelegt sind. Die `for`-Schleife durchläuft diese Liste und gibt die einzelnen Worte aus.\n",
    "\n",
    "Die erwartete Ausgabe sieht etwa so aus:\n",
    "```\n",
    "0) mara 1) santangelo 2) was 3) the 4) defending 5) champion 6) however 7) she 8) chose 9) not 10) to 11) compete 12) this 13) yearpetra 14) marti 15) won 16) her 17) maiden 18)  19) title 20) defeating 21) sharon 22) fichman 23) in 24) the 25) final 26)  27) seedsdrawkeyfinalstop 28) halfbottom 29) halfrefer \n",
    "``` \n",
    "\n",
    "Die konkreten Worte kommen dabei aus zufällig ausgewählten Seiten und sind daher i.d.R. unterschiedlich."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-818d02021f64b1d2",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "worte = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "for i, wort in enumerate(worte):\n",
    "    print(f\"{i}) {wort}\", end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schritt 2: Relative Häufigkeiten der Buchstaben bestimmen\n",
    "Uns interessieren aber weniger die Worte, als die einzelnen Buchstaben.\n",
    "\n",
    "**Aufgabe:** Bestimmen Sie die relativen Häufigkeiten der Buchstaben im Text.\n",
    "\n",
    "Dazu verwenden wir ein *Dictionary* `buchstaben`, das zu Anfang leer ist und gehen folgendermaßen vor:\n",
    "1. Wir durchlaufen alle Buchstaben des Textes (wie im Beispiel weiter oben).\n",
    "2. Wir prüfen, ob der aktuelle Buchstabe als *key* im Dictionary vorkommt\n",
    "    1. Falls er nicht vorkommt, fügen wir den Buchstaben als Schlüssel hinzu und setzen den Wert des Schlüssels auf 1.\n",
    "    2. Falls er vorkommt, erhöhen wir den Wert des Eintrags um 1\n",
    "3. Nachdem alle Buchstaben des Textes verarbeitet sind, durchlaufen wir alle Schlüssel des Dictionaries `buchstaben` und teilen jeden Wert durch die Anzahl der Buchstaben im Text. Beispiel: Wenn der Text 1000 Zeichen hat und der Wert `buchstaben['e']` gleich 100 ist, so setzen wir `buchstaben['e']` auf 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "FxxcglRXHbG2",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-260936f127ecf99f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def letter_frequency(text):\n",
    "    buchstaben = {}\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return buchstaben\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-67923f23edd6a020",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test Zelle\n",
    "test_freq = letter_frequency(\"pizza\")\n",
    "assert 'z' in test_freq\n",
    "assert 'e' not in test_freq\n",
    "assert test_freq['z']==0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir haben nun eine Methode `letter_frequency`, mit der wir die relativen Häufigkeiten der Buchstaben eines Textes bestimmen können.\n",
    "Um einen ersten Eindruck von diesen Häufigkeiten zu bekommen, werden wir ein Säulendiagramm erstellen.\n",
    "Dazu verwenden wir die Bibliothek `matplotlib`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "gIE3WSlHSPtF",
    "outputId": "870cc949-d0d6-4268-e397-b90bee8bdf85"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text = random_text(1000, 'de')\n",
    "buchstaben = letter_frequency(text)\n",
    "\n",
    "plt.figure(figsize=(30,5)) \n",
    "\n",
    "x = range(len(buchstaben))\n",
    "y = list(buchstaben.values())\n",
    "x_ticks = list(buchstaben.keys())\n",
    "plt.bar(x, y, align='center')\n",
    "plt.xticks(x, x_ticks, rotation=0, fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie man sieht, sind die Einträge im Dictionary unsortiert.\n",
    "Weder die Schlüssel noch die Werte folgen einer Ordnung.\n",
    "\n",
    "Um die Buchstabenhäufigkeiten aber später vergleichen zu können, wollen wir einen *Vektor* erzeugen, bei dem Buchstaben immer an gleicher Stelle stehen. Z.B. `a` an Index 0, `b` an Index 1, usw.\n",
    "Eine Idee könnte sein, die Schlüssel zu sortieren.\n",
    "Hierbei ist aber Vorsicht geboten, denn es könnt sein, dass ein Buchstabe im Text nicht vorkommt.\n",
    "In dem Fall, hätte der Vektor zu wenige Einträge.\n",
    "\n",
    "Wir verfolgen daher einen anderen Weg.\n",
    "Über eine `for`-Schleife zählen wir alle Buchstaben von *a* bis *z* auf, schauen nach, ob sie im Dictionary enthalten sind und übernehmen den Wert in eine Liste.\n",
    "Ist der Buchstabe nicht enthalten, übernehmen wir den Wert 0.0 in die Liste.\n",
    "\n",
    "Eine Schleife, die alle Buchstaben durchläuft könnte so aussehen\n",
    "```pypthon\n",
    "for i in range(ord('a'), ord('z')+1):\n",
    "    print(chr(i), end=' ')\n",
    "```\n",
    "\n",
    "`ord('a')` liefert den ASCII Code des Zeichens *a*.\n",
    "So kann die Schleife die ASCII Codes von *a* bis *z* durchlaufen.\n",
    "Im Schleifenrumpf erzeugen wir aus dem ASCII Code mit der Typumwandlung `chr` wieder ein Zeichen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wwhZ1ngWoKLS",
    "outputId": "9c6ac4c4-b398-460d-86a7-73fba54a1d14"
   },
   "source": [
    "**Aufgabe:** Schreiben Sie eine Funktion `frequency_vector(d)`, die aus einem Dictionary `d` ein Tupel mit 26 Einträgen erzeugt, in denen jeweils die relative Häufigkeit der Buchstaben von  *a* bis *z* im Text steht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "nkQo4k0mRWDH",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ae2b2ed6957dc9db",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def frequency_vector(d):\n",
    "    f = []\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-2b3f51178f65f3ba",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test Zelle\n",
    "test_d = {'a': 0.5, 'd': 0.5}\n",
    "test_l = [0.0]*26\n",
    "test_l[0]=0.5\n",
    "test_l[3]=0.5\n",
    "assert frequency_vector(test_d)==tuple(test_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In der folgenden Code-Zelle werden die zuvor entwickelten Funktionen verwendet, um die relativen Häufigkeiten der Buchstaben in den Sprachen *Deutsch*, *Englisch*, *Spanisch* und *Französisch* zu bestimmen.\n",
    "Wir verwenden dazu jeweils 10000 Zeichen aus Wikipedia Artikeln.\n",
    "Die Resultate werden im Dictionary `haeufigkeiten` unter den Schlüsseln `'de'`, `'en'`, `'es'` und `'fr'` abgelegt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bOjMsTNGqXvg",
    "outputId": "9a45dd4f-222e-439f-f542-b5ccddf0e008"
   },
   "outputs": [],
   "source": [
    "languages = ['de', 'en', 'es', 'fr']\n",
    "\n",
    "def get_lang_freq(lang):\n",
    "    text = random_text(10000, lang)\n",
    "    buchstaben = letter_frequency(text)\n",
    "    return frequency_vector(buchstaben)\n",
    "\n",
    "haeufigkeiten = {}\n",
    "for l in languages:\n",
    "    haeufigkeiten[l] = get_lang_freq(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schritt 3: Textpassage in einer Sprachen beschaffen\n",
    "\n",
    "Nun haben wir verschiedene Vektoren, die wir als Maßstab für die einzelnen Sprachen verwenden können.\n",
    "Als Nächstes wollen wir überprüfen, ob wir diese Vektoren verwenden können, um für einen neuen Text vorherzusagen, in welcher Sprache er geschrieben ist.\n",
    "\n",
    "Dazu definiert die folgende Code-Zelle die Funktion `get_page_freq`, mit der wir den Inhalt einer speziellen Wikipedia-Seite herunterladen und die relative Häufigkeit der Buchstaben in dieser Seite berechnen können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LnktjcNbs6gB",
    "outputId": "01522105-ddfa-4315-e067-312468d7d470"
   },
   "outputs": [],
   "source": [
    "def get_wiki_page(term, lang='de'): \n",
    "    WIKI = wikipediaapi.Wikipedia(\n",
    "          language=lang,\n",
    "          extract_format=wikipediaapi.ExtractFormat.WIKI\n",
    "    )\n",
    "    page = WIKI.page(term)\n",
    "    assert page.exists()\n",
    "    t = page.text\n",
    "    # Umlaute entfernen\n",
    "    de_table = str.maketrans({'Ä': 'Ae', 'Ö': 'Oe', 'Ü': 'Ue', \n",
    "                    'ä': 'ae', 'ö': 'oe', 'ü': 'ue', 'ß': 'ss'})\n",
    "    t = t.translate(de_table)\n",
    "    # Entferne alles, was kein Buchstabe oder Leerzeichen ist\n",
    "    t_cleaned = re.sub('[^a-zA-Z ]', '', t)\n",
    "    #Alles zu Kleinbuchstaben\n",
    "    return t_cleaned\n",
    "\n",
    "\n",
    "def get_page_freq(term, lang='de'):\n",
    "    text = get_wiki_page(term, lang=lang)\n",
    "    buchstaben = letter_frequency(text)\n",
    "    return frequency_vector(buchstaben)\n",
    "\n",
    "mypage = get_page_freq(\"Hochschule\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schritt 4: Häufigkeiten vergleichen (Fehler bestimmen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An dieser Stelle haben wir fünf Vektoren, je einen, der die Häufigkeiten der Buchstaben in den Sprachen *Deutsch*, *Englisch*, *Spanisch* und *Französisch* beschreibt sowie einen weiteren, mit den relativen Häufigkeiten der Buchstaben in *unserem* Text.\n",
    "Nun wollen wir ausrechnen, zu welchem der vier Sprach-Vektoren unser Buchstaben-Vektor *am ähnlichsten* ist, bzw. zu welchem Sprach-Vektor er die wenigsten Unterschiede aufweist.\n",
    "\n",
    "Wir werden also die einzelnen Buchstaben-Häufigkeiten in unserem Vektor mit denen im Sprach-Vektor *vergleichen*.\n",
    "Mathematisch gesehen, bilden wir die Differenz der Häufigkeiten aller einzelnen Buchstaben.\n",
    "Kommt z.B. in unserem Text das *e* zu 10% und im Sprach-Vektor zu 8% vor, so ist die Abweichung $0.1-0.08=0.02$ für den Buchstaben *e*.\n",
    "\n",
    "Die folgende Abbildung zeigt ein Beispiel anhand zweier Sprachen und den Buchstaben *a, e, i, o, u*.\n",
    "Vergleicht man die Häufigkeiten der Sprachen *1* und *2* jeweils mit der Häufigkeit der Buchstaben im Text, so ergibt sich für jeden Buchstaben ein Fehler. Da der Fehler für die \"gelbe\" Sprache geringer ist, gehen wir davon aus, dass der Text mit einer höheren *Wahrscheinlichkeit* zur (\"gelben\") Sprache 2 als zur (\"blauen\") Sprache 1 gehört.\n",
    "\n",
    "![](https://github.com/fhswf/datasets/raw/main/images/letterfreq.png)\n",
    "\n",
    "Wenn wir nun alle Abweichungen aufsummieren, kann es zu einem Problem kommen.\n",
    "Manche Differenzen werden positiv, andere negativ sein.\n",
    "Eine einfache Summe wird die negativen und positiven Abweichungen gegeneinander aufrechen.\n",
    "\n",
    "Um dieses Problem zu beheben, gibt es verschiedene Möglichkeiten.\n",
    "Man kann die Absolutwerte der Abweichungen aufsummieren, oder auch deren Quadratwerte.\n",
    "In jedem Fall wird die Summe am Ende durch die Anzahl der Einträge des Vektors geteilt, um den Mittleren Fehler zu berechnen.\n",
    "\n",
    "Verwendet man zum Berechnung die Absolutwerte, nennt man das Maß [*Mittlerer absoluter Fehler*](https://de.wikipedia.org/wiki/Mittlerer_absoluter_Fehler) (oder *mean absolute error*), verwendet man die Fehlerquadrate heißt das Maß [*Mittlerer quadratischer Fehler*](https://de.wikipedia.org/wiki/Mittlere_quadratische_Abweichung) (oder *mean squared error*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe:** Implementieren Sie die Funktion `mse` zur Berechnung des Mittleren Quadratischen Fehlers. \n",
    "\n",
    "*Hinweise:*\n",
    "- Die Funktion soll zwei mit `for` iterierbare Objekte `a` und `b` (z.B. *Listen* oder *Tupel*) gleicher Länge als Parameter übergeben bekommen.\n",
    "- Die Funktion berechnet die Differenzen der Werte an gleichen Index-Positionen.\n",
    "- Da diese Differenten positiv oder negativ sein können, bilden wir jeweils das Quadrat und summieren diese quadrierten Fehler-Werte auf.\n",
    "- Am Ende soll die Funktion den Mittleren quadratischen Fehler mit `return` zurückgeben.\n",
    "\n",
    "*Beispiel:* Für die Beiden Listen `x` und `y` ist der mittlere quadratische Fehler gleich 2:\n",
    "```\n",
    "x = [1,2,3,5]\n",
    "y = [3,2,5,5]\n",
    "```\n",
    "\n",
    "$\\text{MSE} = \\frac{(1-3)^2 + (2-2)^2 + (3-5)^2 + (5-5)^2}{4} = \\frac{(-2)^2 + 0^2 + (-2)^2 + 0^2}{4} = \\frac{4 + 0 + 4 + 0}{4} = \\frac{8}{4} = 2$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "jBuvWTb0uNn3",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-60f82f7410b211c4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "cd140542-1727-486c-caaa-dff6c55c9ad1"
   },
   "outputs": [],
   "source": [
    "def mse(a,b):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-2c575835a514bcce",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test Zelle\n",
    "a = [1,2,3,4,5]\n",
    "b = [3,2,5,4,5]\n",
    "assert mse(a,b)==1.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun können wir unsere Vektoren vergleichen und herausfinden, zu welcher Sprache unser Vektor am ähnlichsten ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ItgkQgDUv4DQ",
    "outputId": "47cc177e-d140-4277-c44b-a2d9c9fa7678"
   },
   "outputs": [],
   "source": [
    "def get_prop(mypage, languages):\n",
    "    fehler = {}\n",
    "    for l in languages:\n",
    "        fehler[l] = mse(mypage,languages[l])\n",
    "\n",
    "    fehlersumme = sum(fehler.values())\n",
    "\n",
    "    props = {}\n",
    "    for f in fehler:\n",
    "        props[f] = 100-fehler[f]*100/fehlersumme\n",
    "\n",
    "\n",
    "    prop_sum = sum(props.values())\n",
    "\n",
    "    for f in props:\n",
    "        props[f] = props[f]*100/prop_sum\n",
    "\n",
    "    return props\n",
    "\n",
    "p = get_prop(mypage, haeufigkeiten)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SR1mFXq8v1SP"
   },
   "source": [
    "Das Dictionary `p` enthält die berechneten Wahrscheinlichkeiten, mit denen der Text in den jeweiligen Sprachen verfasst ist.\n",
    "Man sollte sehen, dass bei einem deutschen Text, der key `'de'` den höchsten Wert enthält. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ausblick: n-Gramme statt Buchstaben verwenden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie man sieht, ist die Häufigkeit der verschiedenen Buchstaben ein mögliches Vorhersagekriterium, allerdings kein sehr gutes. Die Wahrscheinlichkeiten für Deutsch und Englisch sind i.d.R. nicht sehr verschieden.\n",
    "\n",
    "Um das Verfahren zu verbessern, könnte man statt einzelne Buchstaben ganze Worte betrachten.\n",
    "Oder alternativ dazu, Sequenzen von $n$ aufeinanderfolgenden Buchstaben, den sogenannten [n-Grammen](https://de.wikipedia.org/wiki/N-Gramm).\n",
    "\n",
    "Wenn man einen Text auf n-Gramme untersucht, betrachtet man Folgen von $n$ Buchstaben von jedem Buchstaben aus.\n",
    "In der folgenden Code-Zelle verwenden wir das Wort *Waschmaschine* als Beispiel.\n",
    "Das Wort hat 13 Buchstaben und besitzt damit 11 Trigramme (3-Gramme) von denen eines (das *sch*) doppelt vorkommt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wort = 'waschmaschine'\n",
    "[wort[i:i+3] for i in range(len(wort)-2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe:** \n",
    "1. Generieren Sie einen zufälligen Text mit 2000 Zeichen\n",
    "2. Teilen Sie den Text so auf, dass Sie die einzelnen Worte in einer Liste ablegen. Berechnen Sie die 3-Gramme für alle Worte im Text und speichern Sie die 3-Gramme in einer Liste\n",
    "3. Es sollen nur die 3-Gramme betrachtet werden. D.h, wenn ein Wort weniger als 3 Buchstaben besitzt, nehmen Sie es nicht in die Liste auf\n",
    "4. Geben Sie die Anzahl aller 3-Gramme aus, die in ihrem Text enthalten sind\n",
    "5. Geben Sie die Anzahl aller eindeutigen 3-Gramme aus, d.h. ohne doppelte Vorkommen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-9d095194ccd96d1f",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
